---
title: "A3_Methods_3"
author: "Tilde Sloth"
date: "11/2/2022"
output: html_document
---

# Assignment 3: Machine Learning

## Part I - Simulating data

Use the meta-analysis reported in Parola et al (2020), create a simulated dataset with 100 matched pairs of schizophrenia and controls, each participant producing 10 repeated measures (10 trials with their speech recorded). for each of these "recordings" (data points) produce 10 acoustic measures: 6 from the meta-analysis, 4 with just random noise. Do the same for a baseline dataset including only 10 noise variables. Tip: see the slides for the code. 
#### Loading packages
```{r}
pacman::p_load(tidyverse, brms, bayesplot, rstanarm, msm, cmdstanr, recipes, caret, tidytext, tidymodels, DALEXtra)
pacman::p_load(tidyverse, brms, bayesplot, rstanarm, msm, cmdstanr, tidymodels, readr, broom.mixed, dotwhisker, multilevelmod, recipes, caret, klaR)
pacman::p_load(caret)
pacman::p_load(DALEX, DALEXtra)
pacman::p_load(tidytext)
set.seed(123)
```

```{r}
#population size
n <- 200 #for both groups
trials <- 10

#different effect sizes: 6 from meta analysis, 4 for random noise 
InformedEffectMean <- c(rep(0,4), -0.23096087, -0.55698815, -0.05472132, -0.14332350, 0.20377619, -0.41653998)
#introducing a skeptic effect mean
SkepticEffectMean <- rep(0,10)

#individual variability from population and across trials and measurement errors
IndividualSD <- 1
TrialSD <- 0.5
Error <- 0.2
```

### Data simulation (LL)
```{r}
Trial <- rep(1:10,100)
id_SZ <- rep(101:200, each=10)
id_CON <- rep(1:100, each=10)

CON <- data.frame(
  ID = id_CON,
  Trial = Trial,
  Condition = "Control") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)

SZ <- data.frame(
  ID = id_SZ,
  Trial = Trial,
  Condition = "Schizophrenia") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)
```


```{r rnorm for SZ}
for (c in 1:1000){
  SZ[c,4:13] <- Map(rnorm,n=1,mean = InformedEffectMean/2, sd = IndividualSD)
}
for (c in 1:1000){
  CON[c,4:13] <- Map(rnorm,n=1,mean = (-InformedEffectMean)/2, sd = IndividualSD)
}

informed <- rbind(SZ,CON)
```

```{r}
CON_S <- data.frame(
  ID = id_CON,
  Trial = Trial,
  Condition = "Control") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)

SZ_S <- data.frame(
  ID = id_SZ,
  Trial = Trial,
  Condition = "Schizophrenia") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)
```

```{r}
for (c in 1:1000){
  SZ_S[c,4:13] <- Map(rnorm, n = 1, mean = SkepticEffectMean/2, sd = IndividualSD)
}
for (c in 1:1000){
  CON_S[c,4:13] <- Map(rnorm, n = 1, mean = (-SkepticEffectMean)/2, sd = IndividualSD)
}

Skeptic <- rbind(SZ_S,CON_S)
```

### Plotting simulated data (TS)
##### Plotting the variables for the informed simulation
```{r}
informed <- informed %>% 
  mutate(Condition = as.factor(Condition))

plot1 <- informed %>% 
  ggplot(aes(v1, fill = Condition)) + geom_density() + xlim(-4,4)

plot2 <- informed %>% 
  ggplot(aes(v2, fill = Condition)) + geom_density()+ xlim(-4,4)

plot3 <- informed %>% 
  ggplot(aes(V3, fill = Condition)) + geom_density()+ xlim(-4,4)

plot4 <- informed %>% 
  ggplot(aes(v4, fill = Condition)) + geom_density()+ xlim(-4,4)

plot5 <- informed %>% 
  ggplot(aes(v5, fill = Condition)) + geom_density()+ xlim(-4,4)

plot6 <- informed %>% 
  ggplot(aes(v6, fill = Condition)) + geom_density()+ xlim(-4,4)

plot7 <- informed %>% 
  ggplot(aes(v7, fill = Condition)) + geom_density()+ xlim(-4,4)

plot8 <- informed %>% 
  ggplot(aes(v8, fill = Condition)) + geom_density()+ xlim(-4,4)

plot9 <- informed %>% 
  ggplot(aes(v9, fill = Condition)) + geom_density()+ xlim(-4,4)

plot10 <- informed %>% 
  ggplot(aes(v10, fill = Condition)) + geom_density()+ xlim(-4,4)

gridExtra::grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10 )


```
##### Plotting the variables for the skeptic simulations
```{r}
Skeptic <- Skeptic %>% 
  mutate(Condition = as.factor(Condition))

plot1S <- Skeptic %>% 
  ggplot(aes(v1, fill = Condition)) + geom_density()+ xlim(-4,4)

plot2S <- Skeptic %>% 
  ggplot(aes(v2, fill = Condition)) + geom_density()+ xlim(-4,4)

plot3S <- Skeptic %>% 
  ggplot(aes(V3, fill = Condition)) + geom_density()+ xlim(-4,4)

plot4S <- Skeptic %>% 
  ggplot(aes(v4, fill = Condition)) + geom_density()+ xlim(-4,4)

plot5S <- Skeptic %>% 
  ggplot(aes(v5, fill = Condition)) + geom_density()+ xlim(-4,4)

plot6S <- Skeptic %>% 
  ggplot(aes(v6, fill = Condition)) + geom_density()+ xlim(-4,4)

plot7S <- Skeptic %>% 
  ggplot(aes(v7, fill = Condition)) + geom_density()+ xlim(-4,4)

plot8S <- Skeptic %>% 
  ggplot(aes(v8, fill = Condition)) + geom_density()+ xlim(-4,4)

plot9S <- Skeptic %>% 
  ggplot(aes(v9, fill = Condition)) + geom_density()+ xlim(-4,4)

plot10S <- Skeptic %>% 
  ggplot(aes(v10, fill = Condition)) + geom_density()+ xlim(-4,4)

gridExtra::grid.arrange(plot1S, plot2S, plot3S, plot4S, plot5S, plot6S, plot7S, plot8S, plot9S, plot10S )


```

## Part II - ML pipeline on simulated data

On the two simulated datasets (separately) build a machine learning pipeline: i) create a data budget (e.g. balanced training and test sets); ii) pre-process the data (e.g. scaling the features); iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); iv) assess performance on the test set; v) discuss whether performance is as expected and feature importance is as expected.

Bonus question: replace the bayesian multilevel regression with a different algorithm, e.g. SVM or random forest (but really, anything you'd like to try).

### i) create a data budget (EL)

```{r}
informed <- informed %>% 
  mutate(pair=ID) %>% 
  mutate(pair= ifelse(ID > 100, ID-100, ID) )
#if ID is above 100 subtract 100 from ID if not keep the id

Skeptic <- Skeptic %>% 
  mutate(pair=ID) %>% 
  mutate(pair= ifelse(ID > 100, ID-100, ID) )
```

```{r}
# splitting informed into test and train
sample1 <- sample(seq(100), 80)

informed_train <- subset(informed, pair %in% sample1)

informed_test <- subset(informed, !pair %in% sample1)

# splitting skeptic into test and train
sample2 <- sample(seq(100), 80)

Skeptic_train <- subset(Skeptic, pair %in% sample2)

Skeptic_test <- subset(Skeptic, !pair %in% sample2)

# subset conditioned by if column is in the sample column 
```

### ii) pre-process the data (TS & NV)
```{r}
rec_informed <- informed_train %>% 
  recipe(Condition ~ .) %>% 
  update_role(ID, pair, new_role = "ID") %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_dummy(Condition) %>% 
  prep(training = informed_train, retain = TRUE)

summary(rec_informed)

rec_skeptic <-Skeptic_train %>% 
  recipe(Condition ~ .) %>% 
  update_role(ID, pair, new_role = "ID") %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_dummy(Condition) %>% 
  prep(training = Skeptic_train, retain = TRUE)

summary(rec_skeptic)

#Once the data are ready for transformation, the juices() extract transformed training set while the bake() function create a new testing set.

informed_train_s <- juice(rec_informed)
skeptic_train_s <- juice(rec_skeptic)

informed_test_s <- bake(rec_informed, new_data = informed_test)
skeptic_test_s <- bake(rec_skeptic, new_data = Skeptic_test)

informed_train_s <- informed_train_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

informed_test_s <- informed_test_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

skeptic_train_s <- skeptic_train_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

skeptic_test_s <- skeptic_test_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

```

### iii) fit and assess a classification algorithm on the training data (TS & EL)

```{r}
informed_train_s %>% 
  mutate(Condition = as.numeric(Condition)-1) %>% 
  ggplot() +
  geom_point(aes(v6, Condition, color = Condition))+
  geom_smooth(aes(v6, Condition), method = "glm", method.args = list(family = "binomial"))+ theme_bw()


skeptic_train_s %>% 
    mutate(Condition = as.numeric(Condition)-1) %>% 
  ggplot() +
  geom_point(aes(v6, Condition, color = Condition))+
  geom_smooth(aes(v6, Condition), method = "glm", method.args = list(family = "binomial"))+ theme_bw()

```


```{r}
#informed model
pitch_f0 <- bf(Condition ~ 1 + v1 + v2 + V3 + v4 + v5 + v6 + v7 + v8 + v9 + v10)

get_prior(pitch_f0, informed_train_s, family = bernoulli)

pitch_p0 <- c(
  prior(normal(0,1), class = Intercept),
  prior(normal(0,0.3), class = b)
)

pitch_m0 <- brm(
  pitch_f0,
  informed_train_s,
  family = bernoulli,
  prior = pitch_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)

pp_check(pitch_m0, ndraws=100)

summary(pitch_m0)
```

```{r}
posterior <- as_draws_df(pitch_m0)

p1 <- ggplot(posterior) + geom_histogram(aes(prior_Intercept), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_Intercept), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of the intercept - informed")

p2 <- ggplot(posterior) + geom_histogram(aes(prior_b), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_v2), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of variable v2 - informed")

gridExtra::grid.arrange(p1, p2)
```


```{r}
#Skeptic model
pitch_m0_s <- brm(
  pitch_f0,
  skeptic_train_s,
  family = bernoulli,
  prior = pitch_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)

pp_check(pitch_m0_s, ndraws=100)

summary(pitch_m0_s)
```

```{r}
posterior <- as_draws_df(pitch_m0_s)

p1s <- ggplot(posterior) + geom_histogram(aes(prior_Intercept), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_Intercept), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of the intercept - skeptic")

p2s <- ggplot(posterior) + geom_histogram(aes(prior_b), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_v2), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of variable v2 - skeptic")

gridExtra::grid.arrange(p1s, p2s)
```


### iv) assess performance on the test set (NV)
```{r}
# AVERAGE CONFUSION MATRIX PREDICTIONS
pacman::p_load(caret)

# Informed train accuracy
informed_train_s1 <- informed_train_s
informed_train_s1$PredictionPerc0 <- predict(pitch_m0)[, 1]
informed_train_s1$Predictions0[informed_train_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
informed_train_s1$Predictions0[informed_train_s1$PredictionPerc0 <= 0.5] <- "Control"

informed_train_s1 <- informed_train_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

# Informed test accuracy
informed_test_s1 <- informed_test_s
informed_test_s1$PredictionPerc0 <- predict(pitch_m0, newdata = informed_test_s1, allow_new_levels = T)[, 1]
informed_test_s1$Predictions0[informed_test_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
informed_test_s1$Predictions0[informed_test_s1$PredictionPerc0 <= 0.5] <- "Control"

informed_test_s1 <- informed_test_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

# Skeptic train accuracy
skeptic_train_s1 <- skeptic_train_s
skeptic_train_s1$PredictionPerc0 <- predict(pitch_m0_s)[, 1]
skeptic_train_s1$Predictions0[skeptic_train_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
skeptic_train_s1$Predictions0[skeptic_train_s1$PredictionPerc0 <= 0.5] <- "Control"

skeptic_train_s1 <- skeptic_train_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

#Skeptic test accuracy
skeptic_test_s1 <- skeptic_test_s
skeptic_test_s1$PredictionPerc0 <- predict(pitch_m0_s, newdata = skeptic_test_s1, allow_new_levels = T)[, 1]
skeptic_test_s1$Predictions0[skeptic_test_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
skeptic_test_s1$Predictions0[skeptic_test_s1$PredictionPerc0 <= 0.5] <- "Control"

skeptic_test_s1 <- skeptic_test_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

# Confusion Matrices

confusionMatrix(data = informed_test_s1$Predictions0,
                reference = informed_test_s1$Condition)


confusionMatrix(data = skeptic_test_s1$Predictions0,
                reference = skeptic_test_s1$Condition)
```



### v) discuss whether performance is as expected and feature importance is as expected (EL & LL)

### Accuracy
```{r}
# The performance for the skeptic classification model is 48 %, which is very bad since it is below change
# The performance for the informed classification model is 67 %
```

### Feature selection
```{r}
#Importing packages
pacman::p_load(DALEX, DALEXtra)

#Excluding variables from the informed training set
d_inf <- informed_train_s %>% 
  mutate(ID = NULL, Trial = NULL, Condition_Schizophrenia = NULL)

d_skep <- skeptic_train_s %>% 
  mutate(ID = NULL, Trial = NULL, Condition_Schizophrenia = NULL)

#Setting the model type and fitting the model with tidymodels
LogisticRegression_inf <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Condition ~., data = d_inf)

LogisticRegression_skep <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Condition ~., data = d_skep)

#Using the model fit on the data with all information
explainer_lm <- explain_tidymodels(
  LogisticRegression_inf,
  data = informed_train_s,
  y = as.numeric(informed_train$Condition) -1,
  lable = "logReg", 
  verbose = FALSE
)

explainer_lm_skep <- explain_tidymodels(
  LogisticRegression_skep,
  data = skeptic_train_s,
  y = as.numeric(skeptic_train_s$Condition) -1,
  lable = "logReg", 
  verbose = FALSE
)
```


```{r}
set.seed(123)
# One for informed
explainer_lm %>% model_parts() %>% 
  filter(variable != "pair" & # Discard the mentioned variables
           variable != "Trial" &
           variable != "ID" &
           variable != "Condition_Schizophrenia" &
           variable != "Condition") %>% 
  plot(show_boxplots = FALSE) + ggtitle("Feature importance informed")

# One for skeptic
explainer_lm_skep %>% model_parts() %>% 
  filter(variable != "pair" &
           variable != "Trial" &
           variable != "ID" &
           variable != "Condition_Schizophrenia" &
           variable != "Condition") %>% 
  plot(show_boxplots = FALSE) + ggtitle("Feature importance skeptic")
```


```{r}
#Plotting the slope for each variable according to how much it predicts Schizophrenia
model_profile_lm1 <- model_profile(explainer_lm, type = "partial", variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10"))

model_profile_lm1_skep <- model_profile(explainer_lm_skep, type = "partial", variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10"))

plot(model_profile_lm1, variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10")) + ylim(0,1)

plot(model_profile_lm1_skep, variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10")) + ylim(0,1)
```




## Part III - Applying the ML pipeline to empirical data

Download the empirical dataset from brightspace and apply your ML pipeline to the new data, adjusting where needed. Warning: in the simulated data set we only had 10 features, now you have many more! Such is the life of the ML practitioner. Consider the impact a higher number of features will have on your ML inference, and decide whether you need to cut down the number of features before running the pipeline (or alternatively expand the pipeline to add feature selection).


```{r}
d <- read_csv("Ass3_empiricalData1.csv")
pacman::p_load(tidytext)

# Only selecting the numeric variables, and adding Diagnosis afterwards.
d_num <- select_if(d, is.numeric)
d_num$Condition <- d$Diagnosis

#Splitting the data set into train and test 
sample_emp <- sample(seq(100,448), 80)

train_empirical <- subset(d_num, PatID %in% sample_emp)

test_empirical <- subset(d_num, !PatID %in% sample_emp)


```



### Cumulative variance explained by the number of components (NV)
```{r}
# preparing the recipe for 
rec_PCA <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), threshold = 1) %>% 
  prep(training = train_empirical, retain = T)
  
# PLOTTING THE CUMULATIVE VARIANCE EXPLAINED BY NUMBER OF COMPONENTS
# extracting variance explained by the different components
PCA_variance <- as.tibble(t(summary(rec_PCA$steps[[2]]$res)$importance))

# adding number of PCA column
PCA_variance <- rowid_to_column(PCA_variance, "Number of component")

# plotting the cumulative variance explained
PCA_variance %>% 
  ggplot(aes(x = `Number of component`, y = `Cumulative Proportion`)) +
  geom_line(col = "blue") + theme_classic() + xlim(0, 100) +
  labs(title = "Cumulative variance explained by components")+
  ylab("Cumulative explained variance")

# it looks like most of the variance is captured by the first 9 components
```
### Principal compenent analysis (NV & EL)
Model with 3 PCAs
```{r}
# Setting up a recipe using 3 PCAs
rec_PCA3 <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 3) %>% 
  prep(training = train_empirical, retain = T)

# Prepping the data frame, which is needed to move on
pca_rec_train3 <- juice(rec_PCA3)
pca_rec_test3 <- bake(rec_PCA3, new_data = test_empirical)

# Applying the model
real_f0 <- bf(Condition ~ 1 + .)

real_p0 <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 0.3), class = b))

real_m0_3 <- brm(
  real_f0,
  pca_rec_train3,
  family = bernoulli,
  prior = real_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 8,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1")))
```

Model with 6 PCAs
```{r}
rec_PCA6 <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 6) %>% 
  prep(training = train_empirical, retain = T)

# Prepping the data frame, which is needed to move on
pca_rec_train6 <- juice(rec_PCA6)
pca_rec_test6 <- bake(rec_PCA6, new_data = test_empirical)

# Applying the model
real_m0_6 <- update(
  real_m0_3, newdata = pca_rec_train6)
```

MODEL WITH 9 PCA
```{r}
rec_PCA9 <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 9) %>% 
  prep(training = train_empirical, retain = T)

# Prepping the data frame, which is needed to move on
pca_rec_train9 <- juice(rec_PCA9)
pca_rec_test9 <- bake(rec_PCA9, new_data = test_empirical)

# Applying the model
real_m0_9 <- update(
  real_m0_3, newdata = pca_rec_train9)

# Expanding the recipe into a data frame, which is needed for it to be plotted below:
tidied_pca <- tidy(rec_PCA9, 2)

# Exploring results of PCA. These look at the top 9 components.
tidied_pca %>% 
  filter(component %in% paste0("PC", 1:9)) %>% 
  mutate(component = fct_inorder(component)) %>% 
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = F) +
  facet_wrap(~ component, nrow = 1) +
  labs(y = NULL)

# Ranked results of PCA. Looks at the five most influencial components, and inside these it ranks the most influential variables (If they are blue they are positive for the component, red negative.)
tidied_pca %>% 
  filter(component %in% paste0("PC", 1:9)) %>% 
  group_by(component) %>% 
  top_n(8, abs(value)) %>% 
  ungroup() %>% 
  mutate(terms = reorder_within(terms, abs(value), component)) %>% 
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~ component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )
```

### Evaluation
```{r}
# Evaluation using predictions
# setting up a function for evaluating:
pca_eval<- function(test_data, model){

eval <- test_data
eval$Predictions0 <- NA
eval$PredictionPerc0 <- predict(model, newdata = test_data, allow_new_levels = T)[, 1]
eval$Predictions0[eval$PredictionPerc0 > 0.5] <- "Schizophrenia"
eval$Predictions0[eval$PredictionPerc0 <= 0.5] <- "Control"

eval1 <- eval %>% 
  mutate(
    Condition =
      ifelse(Condition=="CT", "Control", "Schizophrenia"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
      
  )
return(eval1)
}

eval_pca3 <- pca_eval(pca_rec_test3, real_m0_3)

eval_pca6 <- pca_eval(pca_rec_test6, real_m0_6)

eval_pca9 <- pca_eval(pca_rec_test9, real_m0_9)
```

Creating some confusion matrices to visualize accuracy of models
```{r}
# setting up a function for confusion matrices
ConfMatrix <- function(testdata){
confusionMatrix(data = testdata$Predictions0,
                reference = testdata$Condition)
}

#3 PCAs
ConfMatrix(eval_pca3)

#6 PCAs
ConfMatrix(eval_pca6)

#9 PCAs
ConfMatrix(eval_pca9)
```



