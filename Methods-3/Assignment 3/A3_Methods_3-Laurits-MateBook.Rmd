---
title: "A3_Methods_3"
author: "Laurits Lyngb√¶k"
date: "11/2/2022"
output:
  pdf_document: default
  html_document: default
---

# Assignment 3: Machine Learning

## Part I - Simulating data

Use the meta-analysis reported in Parola et al (2020), create a simulated dataset with 100 matched pairs of schizophrenia and controls, each participant producing 10 repeated measures (10 trials with their speech recorded). for each of these "recordings" (data points) produce 10 acoustic measures: 6 from the meta-analysis, 4 with just random noise. Do the same for a baseline dataset including only 10 noise variables. Tip: see the slides for the code. 
#### Loading packages
```{r}
pacman::p_load(tidyverse, brms, bayesplot, rstanarm, msm, cmdstanr, tidymodels, readr, broom.mixed, dotwhisker, multilevelmod, recipes, caret, klaR)
pacman::p_load(caret)
pacman::p_load(DALEX, DALEXtra)
pacman::p_load(tidytext)


set.seed(123)
```

```{r}
#population size
n <- 200 #for both groups
trials <- 10

#different effect sizes: 6 from meta analysis, 4 for random noise 
InformedEffectMean <- c(rep(0,4), -0.23096087, -0.55698815, -0.05472132, -0.14332350, 0.20377619, -0.41653998)
#introducing a skeptic effect mean
SkepticEffectMean <- rep(0,10)

#individual variability from population and across trials and measurement errors
IndividualSD <- 1
TrialSD <- 0.5
Error <- 0.2
```

### 03/11 13.54 bedste skud

```{r}
Trial <- rep(1:10,100)
id_SZ <- rep(101:200, each=10)
id_CON <- rep(1:100, each=10)

CON <- data.frame(
  ID = id_CON,
  Trial = Trial,
  Condition = "Control") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)

SZ <- data.frame(
  ID = id_SZ,
  Trial = Trial,
  Condition = "Schizophrenia") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)
```


```{r rnorm for SZ}
for (c in 1:1000){
  SZ[c,4:13] <- Map(rnorm,n=1,mean = InformedEffectMean/2, sd = IndividualSD)
}
for (c in 1:1000){
  CON[c,4:13] <- Map(rnorm,n=1,mean = (-InformedEffectMean)/2, sd = IndividualSD)
}

informed <- rbind(SZ,CON)
```

```{r}
CON_S <- data.frame(
  ID = id_CON,
  Trial = Trial,
  Condition = "Control") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)

SZ_S <- data.frame(
  ID = id_SZ,
  Trial = Trial,
  Condition = "Schizophrenia") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)
```

```{r rnorm for SZ}
for (c in 1:1000){
  SZ_S[c,4:13] <- Map(rnorm, n = 1, mean = SkepticEffectMean/2, sd = IndividualSD)
}
for (c in 1:1000){
  CON_S[c,4:13] <- Map(rnorm, n = 1, mean = (-SkepticEffectMean)/2, sd = IndividualSD)
}

Skeptic <- rbind(SZ_S,CON_S)
```

```{r}
informed <- informed %>% 
  mutate(Condition = as.factor(Condition))

plot1 <- informed %>% 
  ggplot(aes(v1, fill = Condition)) + geom_density()

plot2 <- informed %>% 
  ggplot(aes(v2, fill = Condition)) + geom_density()

plot3 <- informed %>% 
  ggplot(aes(V3, fill = Condition)) + geom_density()

plot4 <- informed %>% 
  ggplot(aes(v4, fill = Condition)) + geom_density()

plot5 <- informed %>% 
  ggplot(aes(v5, fill = Condition)) + geom_density()

plot6 <- informed %>% 
  ggplot(aes(v6, fill = Condition)) + geom_density()

plot7 <- informed %>% 
  ggplot(aes(v7, fill = Condition)) + geom_density()

plot8 <- informed %>% 
  ggplot(aes(v8, fill = Condition)) + geom_density()

plot9 <- informed %>% 
  ggplot(aes(v9, fill = Condition)) + geom_density()

plot10 <- informed %>% 
  ggplot(aes(v10, fill = Condition)) + geom_density()

gridExtra::grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10 )


```

```{r}
Skeptic <- Skeptic %>% 
  mutate(Condition = as.factor(Condition))

plot1S <- Skeptic %>% 
  ggplot(aes(v1, fill = Condition)) + geom_density()

plot2S <- Skeptic %>% 
  ggplot(aes(v2, fill = Condition)) + geom_density()

plot3S <- Skeptic %>% 
  ggplot(aes(V3, fill = Condition)) + geom_density()

plot4S <- Skeptic %>% 
  ggplot(aes(v4, fill = Condition)) + geom_density()

plot5S <- Skeptic %>% 
  ggplot(aes(v5, fill = Condition)) + geom_density()

plot6S <- Skeptic %>% 
  ggplot(aes(v6, fill = Condition)) + geom_density()

plot7S <- Skeptic %>% 
  ggplot(aes(v7, fill = Condition)) + geom_density()

plot8S <- Skeptic %>% 
  ggplot(aes(v8, fill = Condition)) + geom_density()

plot9S <- Skeptic %>% 
  ggplot(aes(v9, fill = Condition)) + geom_density()

plot10S <- Skeptic %>% 
  ggplot(aes(v10, fill = Condition)) + geom_density()

gridExtra::grid.arrange(plot1S, plot2S, plot3S, plot4S, plot5S, plot6S, plot7S, plot8S, plot9S, plot10S )


```

## Part II - ML pipeline on simulated data

On the two simulated datasets (separately) build a machine learning pipeline: i) create a data budget (e.g. balanced training and test sets); ii) pre-process the data (e.g. scaling the features); iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); iv) assess performance on the test set; v) discuss whether performance is as expected and feature importance is as expected.

Bonus question: replace the bayesian multilevel regression with a different algorithm, e.g. SVM or random forest (but really, anything you'd like to try).

### i) create a data budget (e.g. balanced training and test sets)

Creating a new pair column
```{r}
informed <- informed %>% 
  mutate(pair=ID) %>% 
  mutate(pair= ifelse(ID > 100, ID-100, ID) )
#if ID is above 100 subtract 100 from ID if not keep the id

Skeptic <- Skeptic %>% 
  mutate(pair=ID) %>% 
  mutate(pair= ifelse(ID > 100, ID-100, ID) )
```

```{r}
# splitting informed into test and train
sample1 <- sample(seq(100), 80)

informed_train <- subset(informed, pair %in% sample1)

informed_test <- subset(informed, !pair %in% sample1)

# splitting skeptic into test and train
sample2 <- sample(seq(100), 80)

Skeptic_train <- subset(Skeptic, pair %in% sample2)

Skeptic_test <- subset(Skeptic, !pair %in% sample2)

# subset conditioned by if column is in the sample column 
```

### ii) pre-process the data (e.g. scaling the features);
```{r}
rec_informed <- informed_train %>% 
  recipe(Condition ~ .) %>% 
  update_role(ID, pair, new_role = "ID") %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_dummy(Condition) %>% 
  prep(training = informed_train, retain = TRUE)

summary(rec_informed)

rec_skeptic <-Skeptic_train %>% 
  recipe(Condition ~ .) %>% 
  update_role(ID, pair, new_role = "ID") %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_dummy(Condition) %>% 
  prep(training = Skeptic_train, retain = TRUE)

summary(rec_skeptic)

#Once the data are ready for transformation, the juices() extract transformed training set while the bake() function create a new testing set.

informed_train_s <- juice(rec_informed)
skeptic_train_s <- juice(rec_skeptic)

informed_test_s <- bake(rec_informed, new_data = informed_test)
skeptic_test_s <- bake(rec_skeptic, new_data = Skeptic_test)

informed_train_s <- informed_train_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

informed_test_s <- informed_test_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

skeptic_train_s <- skeptic_train_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

skeptic_test_s <- skeptic_test_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

```

iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); 

```{r}
informed_train_s %>% 
  mutate(Condition = as.numeric(Condition)-1) %>% 
  ggplot() +
  geom_point(aes(v6, Condition, color = Condition))+
  geom_smooth(aes(v6, Condition), method = "glm", method.args = list(family = "binomial"))+ theme_bw()


skeptic_train_s %>% 
    mutate(Condition = as.numeric(Condition)-1) %>% 
  ggplot() +
  geom_point(aes(v6, Condition, color = Condition))+
  geom_smooth(aes(v6, Condition), method = "glm", method.args = list(family = "binomial"))+ theme_bw()

```


```{r}
#informed model
pitch_f0 <- bf(Condition ~ 1 + v1 + v2 + V3 + v4 + v5 + v6 + v7 + v8 + v9 + v10)

get_prior(pitch_f0, informed_train_s, family = bernoulli)

pitch_p0 <- c(
  prior(normal(0,1), class = Intercept),
  prior(normal(0,0.3), class = b)
)

pitch_m0 <- brm(
  pitch_f0,
  informed_train_s,
  family = bernoulli,
  prior = pitch_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)

pp_check(pitch_m0, ndraws=100)

summary(pitch_m0)
```

```{r}
posterior <- as_draws_df(pitch_m0)

p1 <- ggplot(posterior) + geom_histogram(aes(prior_Intercept), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_Intercept), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of the intercept - informed")

p2 <- ggplot(posterior) + geom_histogram(aes(prior_b), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_v2), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of variable v2 - informed")

gridExtra::grid.arrange(p1, p2)
```


```{r}
#Skeptic model
pitch_m0_s <- brm(
  pitch_f0,
  skeptic_train_s,
  family = bernoulli,
  prior = pitch_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)

pp_check(pitch_m0_s, ndraws=100)

summary(pitch_m0_s)
```

```{r}
posterior <- as_draws_df(pitch_m0_s)

p1s <- ggplot(posterior) + geom_histogram(aes(prior_Intercept), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_Intercept), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of the intercept - skeptic")

p2s <- ggplot(posterior) + geom_histogram(aes(prior_b), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_v2), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of variable v2 - skeptic")

gridExtra::grid.arrange(p1s, p2s)
```


iv) assess performance on the test set; 
```{r}
# AVERAGE CONFUSION MATRIX PREDICTIONS


# Informed train accuracy
informed_train_s1 <- informed_train_s
informed_train_s1$PredictionPerc0 <- predict(pitch_m0)[, 1]
informed_train_s1$Predictions0[informed_train_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
informed_train_s1$Predictions0[informed_train_s1$PredictionPerc0 <= 0.5] <- "Control"

informed_train_s1 <- informed_train_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

# Informed test accuracy
informed_test_s1 <- informed_test_s
informed_test_s1$PredictionPerc0 <- predict(pitch_m0, newdata = informed_test_s1, allow_new_levels = T)[, 1]
informed_test_s1$Predictions0[informed_test_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
informed_test_s1$Predictions0[informed_test_s1$PredictionPerc0 <= 0.5] <- "Control"

informed_test_s1 <- informed_test_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

# Skeptic train accuracy
skeptic_train_s1 <- skeptic_train_s
skeptic_train_s1$PredictionPerc0 <- predict(pitch_m0_s)[, 1]
skeptic_train_s1$Predictions0[skeptic_train_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
skeptic_train_s1$Predictions0[skeptic_train_s1$PredictionPerc0 <= 0.5] <- "Control"

skeptic_train_s1 <- skeptic_train_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

#Skeptic test accuracy
skeptic_test_s1 <- skeptic_test_s
skeptic_test_s1$PredictionPerc0 <- predict(pitch_m0_s, newdata = skeptic_test_s1, allow_new_levels = T)[, 1]
skeptic_test_s1$Predictions0[skeptic_test_s1$PredictionPerc0 > 0.5] <- "Schizophrenia"
skeptic_test_s1$Predictions0[skeptic_test_s1$PredictionPerc0 <= 0.5] <- "Control"

skeptic_test_s1 <- skeptic_test_s1 %>% 
  mutate(Condition = 
    ifelse(Condition == "1", "Schizophrenia", "Control"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
  )

# Confusion Matrices

confusionMatrix(data = informed_test_s1$Predictions0,
                reference = informed_test_s1$Condition)


confusionMatrix(data = skeptic_test_s1$Predictions0,
                reference = skeptic_test_s1$Condition)
```

Confusion Matrices with uncertainty - DOESN'T WORK :((
```{r}
# Setting up the data frame
ConfProb <- tibble(
  expand_grid(
    sample = seq(1600),
    setup = c("informed", "skeptic"),
    type = c("training", "test")
  )
)
# Informed probabilities
testProbInf <- inv_logit_scaled(posterior_linpred(pitch_m0, summary = F))
trainProbInf <- inv_logit_scaled(posterior_linpred(pitch_m0, summary = F,
                                                newdata = informed_test_s,
                                                allow_new_levels = T))

# Skeptic probabilities
testProbSkep <- inv_logit_scaled(posterior_linpred(pitch_m0_s, summary = F))
trainProbSkep <- inv_logit_scaled(posterior_linpred(pitch_m0_s, summary = F,
                                                newdata = skeptic_test_s,
                                                allow_new_levels = T))

# for (i in seq(1600)) {
#   informed_train_s$Predictions0 <- as.factor(ifelse(trainProbInf[i,] > 0.5, "Schizophrenia",
#                                                     "Control"))
#   informed_test_s$Predictions0 <- as.factor(ifelse(testProbInf[i,] > 0.5, "Schizophrenia",
#                                                     "Control"))
#   
#   ConfProb$Accuracy[ConfProb$sample == i & ConfProb$setup == "informed" & ConfProb$type ==
#                       "training"] <- accuracy(informed_train_s, truth = Condition, estimate =
#                                                 Predictions0)[, ".estimate"]
#   ConfProb$Accuracy[ConfProb$sample == i & ConfProb$setup == "informed" & ConfProb$type ==
#                       "test"] <- accuracy(informed_test_s, truth = Condition, estimate =
#                                                 Predictions0)[, ".estimate"]
#   ConfProb$Accuracy[ConfProb$sample == i & ConfProb$setup == "skeptic" & ConfProb$type ==
#                       "training"] <- accuracy(skeptic_train_s, truth = Condition, estimate =
#                                                 Predictions0)[, ".estimate"]
#   ConfProb$Accuracy[ConfProb$sample == i & ConfProb$setup == "skeptic" & ConfProb$type ==
#                       "test"] <- accuracy(skeptic_test_s, truth = Condition, estimate =
#                                                 Predictions0)[, ".estimate"]
# }
                                                
```

v) discuss whether performance is as expected and feature importance is as expected.

### Accuracy
```{r}
# The performance for the skeptic classification model is 48 %, which is very bad since it is below change
# The performance for the informed classification model is 67 %
```

### Feature selection
```{r}
#Importing packages


#Excluding variables from the informed training set
d_inf <- informed_train_s %>% 
  mutate(ID = NULL, Trial = NULL, Condition_Schizophrenia = NULL)

d_skep <- skeptic_train_s %>% 
  mutate(ID = NULL, Trial = NULL, Condition_Schizophrenia = NULL)

#Setting the model type and fitting the model with tidymodels
LogisticRegression_inf <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Condition ~., data = d_inf)

LogisticRegression_skep <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(Condition ~., data = d_skep)

#Using the model fit on the data with all information
explainer_lm <- explain_tidymodels(
  LogisticRegression_inf,
  data = informed_train_s,
  y = as.numeric(informed_train$Condition) -1,
  lable = "logReg", 
  verbose = FALSE
)

explainer_lm_skep <- explain_tidymodels(
  LogisticRegression_skep,
  data = skeptic_train_s,
  y = as.numeric(skeptic_train_s$Condition) -1,
  lable = "logReg", 
  verbose = FALSE
)

#Plotting feature importance
explainer_lm %>% model_parts() %>% plot(show_boxplots = FALSE) + ggtitle("Feature importance informed")

explainer_lm_skep %>% model_parts() %>% plot(show_boxplots = FALSE) + ggtitle("Feature importance skeptic")
```


```{r}
#Plotting the slope for each variable according to how much it predicts Schizophrenia
model_profile_lm1 <- model_profile(explainer_lm, type = "partial", variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10"))

model_profile_lm1_skep <- model_profile(explainer_lm_skep, type = "partial", variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10"))

plot(model_profile_lm1, variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10"))

plot(model_profile_lm1_skep, variables = c("v1", "v2", "V3", "v4", "v5", "v6", "v7", "v8", "v9", "v10"))
```




## Part III - Applying the ML pipeline to empirical data

Download the empirical dataset from brightspace and apply your ML pipeline to the new data, adjusting where needed. Warning: in the simulated data set we only had 10 features, now you have many more! Such is the life of the ML practitioner. Consider the impact a higher number of features will have on your ML inference, and decide whether you need to cut down the number of features before running the pipeline (or alternatively expand the pipeline to add feature selection).



```{r}

d <- read_csv("Ass3_empiricalData1.csv")


# Only selecting the numeric variables, and adding Diagnosis afterwards.
d_num <- select_if(d, is.numeric)
d_num$Condition <- d$Diagnosis

#Splitting the data set into train and test 
sample_emp <- sample(seq(100,448), 80)

train_empirical <- subset(d_num, PatID %in% sample_emp)

test_empirical <- subset(d_num, !PatID %in% sample_emp)


```

MODEL WITH 3 PCA
```{r}
rec_PCA3 <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 3) %>% 
  prep(training = train_empirical, retain = T)

# Prepping the data frame, which is needed to move on
pca_rec_train3 <- juice(rec_PCA3)
pca_rec_test3 <- bake(rec_PCA3, new_data = test_empirical)

# Applying the model
real_f0 <- bf(Condition ~ 1 + .)

get_prior(real_f0, pca_rec_train3, family = bernoulli)

real_p0 <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 0.3), class = b))

real_m0_3 <- brm(
  real_f0,
  pca_rec_train3,
  family = bernoulli,
  prior = real_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 6,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1")))
```

MODEL WITH 6 PCA
```{r}
rec_PCA6 <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 6) %>% 
  prep(training = train_empirical, retain = T)

# Prepping the data frame, which is needed to move on
pca_rec_train6 <- juice(rec_PCA6)
pca_rec_test6 <- bake(rec_PCA6, new_data = test_empirical)

# Applying the model


real_m0_6 <- brm(
  real_f0,
  pca_rec_train6,
  family = bernoulli,
  prior = real_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 6,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)


```

MODEL WITH 9 PCA
```{r}
rec_PCA9 <- recipe(~., data = train_empirical) %>% 
  update_role(PatID, new_role = "ID") %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 9) %>% 
  prep(training = train_empirical, retain = T)

# Prepping the data frame, which is needed to move on
pca_rec_train9 <- juice(rec_PCA9)
pca_rec_test9 <- bake(rec_PCA9, new_data = test_empirical)

# Applying the model


real_p0_9 <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 0.3), class = b))

real_m0_9 <- brm(
  real_f0,
  pca_rec_train9,
  family = bernoulli,
  prior = real_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 6,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)

# Expanding the recipe into a data frame, which is needed for it to be plotted below:
tidied_pca <- tidy(pca_prep, 2)

# Exploring results of PCA. These look at the top 5 components.
tidied_pca %>% 
  filter(component %in% paste0("PC", 1:9)) %>% 
  mutate(component = fct_inorder(component)) %>% 
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = F) +
  facet_wrap(~ component, nrow = 1) +
  labs(y = NULL)

# Ranked results of PCA. Looks at the top five components, and inside these it ranks the most influential variables (If they are blue they are positive for the component, red negative.)
tidied_pca %>% 
  filter(component %in% paste0("PC", 1:9)) %>% 
  group_by(component) %>% 
  top_n(8, abs(value)) %>% 
  ungroup() %>% 
  mutate(terms = reorder_within(terms, abs(value), component)) %>% 
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~ component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )

```

### Evaluation
```{r}
# AVERAGE CONFUSION MATRIX PREDICTIONS


pca_eval<- function(test_data, model){

eval_m0_3 <- test_data
eval_m0_3$PredictionPerc0 <- predict(model, newdata = test_data, allow_new_levels = T)[, 1]
eval_m0_3$Predictions0[eval_m0_3$PredictionPerc0 > 0.5] <- "Schizophrenia"
eval_m0_3$Predictions0[eval_m0_3$PredictionPerc0 <= 0.5] <- "Control"

eval_m0_3 <- eval_m0_3 %>% 
  mutate(
    Condition =
      ifelse(Condition=="CT", "Control", "Schizophrenia"),
    Condition = as.factor(Condition),
    Predictions0 = as.factor(Predictions0)
      
  )
}

eval_pca3 <- pca_eval(pca_rec_test3, real_m0_3)

eval_pca6 <- pca_eval(pca_rec_test6, real_m0_6)

eval_pca9 <- pca_eval(pca_rec_test9, real_m0_9)


```

Creating some confusion matrixes to visualize accuracy of models
```{r}
ConfMatrix <- function(testdata){
confusionMatrix(data = testdata$Predictions0,
                reference = testdata$Condition)
}

ConfMatrix(eval_pca3)

ConfMatrix(eval_pca6)

ConfMatrix(eval_pca9)
```

