---
title: "Assignment 3 - Machine Learning"
author: "Elisius, Laurits, Tilde & Niels"
date: "02/11/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 3: Machine Learning

## Part I - Simulating data
Use the meta-analysis reported in Parola et al (2020), create a simulated dataset with 100 matched pairs of schizophrenia and controls, each participant producing 10 repeated measures (10 trials with their speech recorded). for each of these "recordings" (data points) produce 10 acoustic measures: 6 from the meta-analysis, 4 with just random noise. Do the same for a baseline dataset including only 10 noise variables. Tip: see the slides for the code. 
#### Loading packages
```{r}
pacman::p_load(tidyverse, brms, bayesplot, rstanarm, msm, cmdstanr)
set.seed(123)
```

```{r}
#population size
n <- 200 #for both groups
trials <- 10

#different effect sizes: 6 from meta analysis, 4 for random noise 
InformedEffectMean <- c(rep(0,4), -0.23096087, -0.55698815, -0.05472132, -0.14332350, 0.20377619, -0.41653998)
#introducing a skeptic effect mean
SkepticEffectMean <- rep(0,10)

#individual variability from population and across trials and measurement errors
IndividualSD <- 1
TrialSD <- 0.5
Error <- 0.2
```

### 03/11 13.54 bedste skud
```{r}
Trial <- rep(1:10,100)
id_SZ <- rep(101:200, each=10)
id_CON <- rep(1:100, each=10)

CON <- data.frame(
  ID = id_CON,
  Trial = Trial,
  Condition = "Control") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)

SZ <- data.frame(
  ID = id_SZ,
  Trial = Trial,
  Condition = "Schizophrenia") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)
```


```{r rnorm for SZ}
for (c in 1:1000){
  SZ[c,4:13] <- Map(rnorm,n=1,mean = InformedEffectMean/2, sd = IndividualSD)
}
for (c in 1:1000){
  CON[c,4:13] <- Map(rnorm,n=1,mean = (-InformedEffectMean)/2, sd = IndividualSD)
}

informed <- rbind(SZ,CON)
```

```{r}
CON_S <- data.frame(
  ID = id_CON,
  Trial = Trial,
  Condition = "Control") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)

SZ_S <- data.frame(
  ID = id_SZ,
  Trial = Trial,
  Condition = "Schizophrenia") %>% 
  mutate(v1 = NA,
         v2 = NA,
         V3 = NA,
         v4 = NA,
         v5 = NA,
         v6 = NA,
         v7 = NA,
         v8 = NA,
         v9 = NA,
         v10 = NA)
```

```{r rnorm for SZ}
for (c in 1:1000){
  SZ_S[c,4:13] <- Map(rnorm, n = 1, mean = SkepticEffectMean/2, sd = IndividualSD)
}
for (c in 1:1000){
  CON_S[c,4:13] <- Map(rnorm, n = 1, mean = (-SkepticEffectMean)/2, sd = IndividualSD)
}

Skeptic <- rbind(SZ_S,CON_S)
rm(SZ_S, SZ, CON_S, CON)
```


### Plotting the variables
##### Informed simulation
```{r}
informed <- informed %>% 
  mutate(Condition = as.factor(Condition))

plot1 <- informed %>% 
  ggplot(aes(v1, fill = Condition)) + geom_density()

plot2 <- informed %>% 
  ggplot(aes(v2, fill = Condition)) + geom_density()

plot3 <- informed %>% 
  ggplot(aes(V3, fill = Condition)) + geom_density()

plot4 <- informed %>% 
  ggplot(aes(v4, fill = Condition)) + geom_density()

plot5 <- informed %>% 
  ggplot(aes(v5, fill = Condition)) + geom_density()

plot6 <- informed %>% 
  ggplot(aes(v6, fill = Condition)) + geom_density()

plot7 <- informed %>% 
  ggplot(aes(v7, fill = Condition)) + geom_density()

plot8 <- informed %>% 
  ggplot(aes(v8, fill = Condition)) + geom_density()

plot9 <- informed %>% 
  ggplot(aes(v9, fill = Condition)) + geom_density()

plot10 <- informed %>% 
  ggplot(aes(v10, fill = Condition)) + geom_density()

gridExtra::grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10)
rm(plot1, plot2, plot3, plot4, plot5, plot6, plot7, plot8, plot9, plot10)
```
##### Skeptic simulation
```{r}
Skeptic <- Skeptic %>% 
  mutate(Condition = as.factor(Condition))

plot1S <- Skeptic %>% 
  ggplot(aes(v1, fill = Condition)) + geom_density()

plot2S <- Skeptic %>% 
  ggplot(aes(v2, fill = Condition)) + geom_density()

plot3S <- Skeptic %>% 
  ggplot(aes(V3, fill = Condition)) + geom_density()

plot4S <- Skeptic %>% 
  ggplot(aes(v4, fill = Condition)) + geom_density()

plot5S <- Skeptic %>% 
  ggplot(aes(v5, fill = Condition)) + geom_density()

plot6S <- Skeptic %>% 
  ggplot(aes(v6, fill = Condition)) + geom_density()

plot7S <- Skeptic %>% 
  ggplot(aes(v7, fill = Condition)) + geom_density()

plot8S <- Skeptic %>% 
  ggplot(aes(v8, fill = Condition)) + geom_density()

plot9S <- Skeptic %>% 
  ggplot(aes(v9, fill = Condition)) + geom_density()

plot10S <- Skeptic %>% 
  ggplot(aes(v10, fill = Condition)) + geom_density()

gridExtra::grid.arrange(plot1S, plot2S, plot3S, plot4S, plot5S, plot6S, plot7S, plot8S, plot9S, plot10S)
rm(plot1S, plot2S, plot3S, plot4S, plot5S, plot6S, plot7S, plot8S, plot9S, plot10S)
```

## Part II - ML pipeline on simulated data

On the two simulated datasets (separately) build a machine learning pipeline: i) create a data budget (e.g. balanced training and test sets); ii) pre-process the data (e.g. scaling the features); iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); iv) assess performance on the test set; v) discuss whether performance is as expected and feature importance is as expected.

Bonus question: replace the bayesian multilevel regression with a different algorithm, e.g. SVM or random forest (but really, anything you'd like to try).

### i) create a data budget (e.g. balanced training and test sets)

Creating a new pair column
```{r}
informed <- informed %>% 
  mutate(pair=ID) %>% 
  mutate(pair= ifelse(ID > 100, ID-100, ID) ) %>% 
  mutate(dummy = ifelse(Condition == "Schizophrenia", 1, 0)) %>% 
  mutate(dummy = as.factor(dummy))

#if ID is above 100 subtract 100 from ID if not keep the id

Skeptic <- Skeptic %>% 
  mutate(pair=ID) %>% 
  mutate(pair= ifelse(ID > 100, ID-100, ID) )%>% 
  mutate(dummy = ifelse(Condition == "Schizophrenia", 1, 0))%>% 
  mutate(dummy = as.factor(dummy))
```

```{r}
# splitting informed into test and train
sample1 <- sample(seq(100), 80)

informed_train <- subset(informed, pair %in% sample1)

informed_test <- subset(informed, !pair %in% sample1)

# splitting skeptic into test and train
sample2 <- sample(seq(100), 80)

Skeptic_train <- subset(Skeptic, pair %in% sample2)

Skeptic_test <- subset(Skeptic, !pair %in% sample2)

# subset conditioned by if column is in the sample column 
```

### ii) pre-process the data (e.g. scaling the features);
```{r}
informed_train[,4:13] <- scale(informed_train[,4:13])
informed_test[,4:13] <- scale(informed_test[,4:13])

Skeptic_train[,4:13] <- scale(Skeptic_train[,4:13])
Skeptic_test[,4:13] <- scale(Skeptic_test[,4:13])

```
### Preprocessing updated - the tidymodels way
```{r}
rec_informed <- informed_train %>% 
  recipe(Condition ~ .) %>% 
  update_role(ID, pair, new_role = "ID") %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_dummy(Condition) %>% 
  prep(training = informed_train, retain = TRUE)

summary(rec_informed)

rec_skeptic <- Skeptic_train %>% 
  recipe(Condition ~ .) %>% 
  update_role(ID, pair, new_role = "ID") %>% 
  step_scale(all_numeric()) %>% 
  step_center(all_numeric()) %>%
  step_dummy(Condition) %>% 
  prep(training = Skeptic_train, retain = TRUE)

summary(rec_skeptic)

#Once the data are ready for transformation, the juices() extract transformed training set while the bake() function create a new testing set.

#Juice
informed_train_s <- juice(rec_informed)
skeptic_train_s <- juice(rec_skeptic)

#Bake
informed_test_s <- bake(rec_informed, new_data = informed_test)
skeptic_test_s <- bake(rec_skeptic, new_data = Skeptic_test)


informed_train_s <- informed_train_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

skeptic_train_s <- skeptic_train_s %>% 
  mutate(Condition = as.factor(Condition_Schizophrenia))

```

### iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression);
```{r}
pitch_f0 <- bf(Condition ~ 1 + v1 + v2 + V3 + v4 + v5 + v6 + v7 + v8 + v9 + v10)

get_prior(pitch_f0, informed_train_s, family = bernoulli)

pitch_p0 <- c(
  prior(normal(0,1), class = Intercept),
  prior(normal(0,0.3), class = b)
)

pitch_m0 <- brm(
  pitch_f0,
  informed_train_s,
  family = bernoulli,
  prior = pitch_p0,
  sample_prior = T,
  backend = "cmdstanr",
  chains = 2,
  cores = 2,
  threads = threading(2),
  control = list(adapt_delta = 0.9,
                 max_treedepth = 20),
  stan_model_args = list(stanc_options = list("O1"))
)



pp_check(pitch_m0, ndraws=100)
```


```{r}
posterior <- as_draws_df(pitch_m0)

p1 <- ggplot(posterior) + geom_histogram(aes(prior_Intercept), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_Intercept), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of the intercept")

p2 <- ggplot(posterior) + geom_histogram(aes(prior_b), fill = "red", color = "red", alpha = 0.3, bins = 50) + geom_histogram(aes(b_v2), fill = "green", color = "green", alpha = 0.3, bins = 50) + xlab("Prior-posterior update check of variable v2")

gridExtra::grid.arrange(p1, p2)
```

### iv) assess performance on the test set;



### v) discuss whether performance is as expected and feature importance is as expected.


## Part III - Applying the ML pipeline to empirical data

Download the empirical dataset from brightspace and apply your ML pipeline to the new data, adjusting where needed. Warning: in the simulated dataset we only had 10 features, now you have many more! Such is the life of the ML practitioner. Consider the impact a higher number of features will have on your ML inference, and decide whether you need to cut down the number of features before running the pipeline (or alternatively expand the pipeline to add feature selection).


